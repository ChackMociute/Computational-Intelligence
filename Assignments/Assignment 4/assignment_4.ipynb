{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QRBDdr0SEqpT"
   },
   "source": [
    "# Assignment 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8xd57TRzExEr"
   },
   "source": [
    "**Assignment 4: Neural Networks**\n",
    "\n",
    "**Goal**: ​Get familiar with neural networks by implementing them and applying them to image classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yHNgWB1iFDu5"
   },
   "source": [
    "In this assignment we are going to learn about neural networks (NNs). The goal is to implement two neural networks: a fully-connected neural network, a convolutional neural network, and analyze their behavior.\n",
    "\n",
    "The considered task is image classification. We consider a dataset of small natural images (see the additional file) with multiple classes. We aim at formulating a model (a neural network) and learning it using the negative log-likelihood function (i.e., the cross-entropy loss) as the objective function, and the stochastic gradient descent as the optimizer.\n",
    "\n",
    "In this assignment, ​**the code must be implemented in PyTorch**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jxgc7c--P0GH"
   },
   "source": [
    "## 1 Understanding the problem\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oRteDLEPP3eX"
   },
   "source": [
    "The considered problem is about classifying images to $L$ classes. In the first part of the assignment, you are asked get familiar with PyTorch, a deep learning library, and the basics of neural networks, and implement neural-network-based classifiers. For this purpose, we will start with classifying small images (8px x 8px) of handwritten digits to one of 10 classes. The dataset is very small and all experiments could be achieved within a couple of minutes.\n",
    "\n",
    "In the second part, you are asked to implement the whole pipeline for a given dataset by yourself.\n",
    "\n",
    "Please run the code below and spend a while on analyzing the images.\n",
    "\n",
    "If any code line is unclear to you, please read on that in numpy, scipy, matplotlib and PyTorch docs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g4wCnPRz-MaE"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn import datasets\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "EPS = 1.e-7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mRmwbuamRuge"
   },
   "outputs": [],
   "source": [
    "# IF YOU USE COLAB, THIS IS VERY USEFUL! OTHERWISE, PLEASE REMOVE IT.\n",
    "# mount drive: WE NEED IT FOR SAVING IMAGES!\n",
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KEiEJE5sRvjc"
   },
   "outputs": [],
   "source": [
    "# IF YOU USE COLAB, THIS IS VERY USEFUL! OTHERWISE, PLEASE REMOVE IT.\n",
    "# PLEASE CHANGE IT TO YOUR OWN GOOGLE DRIVE!\n",
    "results_dir = '/content/gdrive/My_Drive/Colab Notebooks/TEACHING/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xm4e0Utl-30c"
   },
   "outputs": [],
   "source": [
    "# PLEASE DO NOT REMOVE!\n",
    "# This is a class for the dataset of small (8px x 8px) digits.\n",
    "# Please try to understand in details how it works!\n",
    "class Digits(Dataset):\n",
    "    \"\"\"Scikit-Learn Digits dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, mode='train', transforms=None):\n",
    "        digits = load_digits()\n",
    "        if mode == 'train':\n",
    "            self.data = digits.data[:1000].astype(np.float32)\n",
    "            self.targets = digits.target[:1000]\n",
    "        elif mode == 'val':\n",
    "            self.data = digits.data[1000:1350].astype(np.float32)\n",
    "            self.targets = digits.target[1000:1350]\n",
    "        else:\n",
    "            self.data = digits.data[1350:].astype(np.float32)\n",
    "            self.targets = digits.target[1350:]\n",
    "\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample_x = self.data[idx]\n",
    "        sample_y = self.targets[idx]\n",
    "        if self.transforms:\n",
    "            sample_x = self.transforms(sample_x)\n",
    "        return (sample_x, sample_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bnDz_yGeuOnh"
   },
   "outputs": [],
   "source": [
    "# PLEASE DO NOT REMOVE\n",
    "# Here, we plot some images (8px x 8px).\n",
    "digits = load_digits()\n",
    "x = digits.data[:16].astype(np.float32)\n",
    "\n",
    "fig_data, axs = plt.subplots(4,4,figsize=(4, 4))\n",
    "fig_data.tight_layout()\n",
    "\n",
    "for i in range(4):\n",
    "    for j in range(4):\n",
    "        img = np.reshape(x[4*i+j],(8,8))\n",
    "        axs[i,j].imshow(img, cmap='gray')\n",
    "        axs[i,j].axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wgc_GFOyRBEi"
   },
   "source": [
    "## 2 Neural Networks for Digits (4pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gDVf1vyORGUB"
   },
   "source": [
    "In this assignment, you are asked to implement a neural network (NN) classifier. Please take a look at the class below and fill in the missing parts.\n",
    "\n",
    "NOTE: Please pay attention to the inputs and outputs of each function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iwuEfxSKpFtD"
   },
   "source": [
    "### 2.1 Neural Network Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9FThxxdkpKcQ"
   },
   "source": [
    "Below, we have two helper modules (layers) that can be used to reshape and flatten a tensor. They are useful for creating sequentials with convolutional layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5AB5Ch63Ak01"
   },
   "outputs": [],
   "source": [
    "# PLEASE DO NOT REMOVE!\n",
    "# Here are two auxiliary functions that can be used for a convolutional NN (CNN).\n",
    "\n",
    "# This module reshapes an input (matrix -> tensor).\n",
    "class Reshape(nn.Module):\n",
    "    def __init__(self, size):\n",
    "        super(Reshape, self).__init__()\n",
    "        self.size = size # a list\n",
    "  \n",
    "    def forward(self, x):\n",
    "        assert x.shape[1] == np.prod(self.size)\n",
    "        return x.view(x.shape[0], *self.size)\n",
    "\n",
    "# This module flattens an input (tensor -> matrix) by blending dimensions \n",
    "# beyond the batch size.\n",
    "class Flatten(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Flatten, self).__init__()\n",
    "  \n",
    "    def forward(self, x):\n",
    "        return x.view(x.shape[0], -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x3i9R3NmpUY3"
   },
   "source": [
    "Below is the main class for a classifier parameterized by a neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Vtv_pAkmOrS3"
   },
   "outputs": [],
   "source": [
    "#=========\n",
    "# GRADING:\n",
    "# 0 \n",
    "# 0.5 pt if code works but it is explained badly\n",
    "# 1.0 pt if code works and it is explained well\n",
    "#=========\n",
    "# Implement a neural network (NN) classifier. \n",
    "class ClassifierNeuralNet(nn.Module):\n",
    "    def __init__(self, classnet):\n",
    "        super(ClassifierNeuralNet, self).__init__()\n",
    "        # We provide a sequential module with layers and activations\n",
    "        self.classnet = classnet\n",
    "        # The loss function (the negative log-likelihood)\n",
    "        self.nll = nn.NLLLoss(reduction='none') #it requires log-softmax as input!!\n",
    "\n",
    "    # This function classifies an image x to a class.\n",
    "    # The output must be a class label (long).\n",
    "    def classify(self, x):\n",
    "        #------\n",
    "        # PLEASE FILL IN\n",
    "        # y_pred = ...\n",
    "\n",
    "        return y_pred\n",
    "\n",
    "    # This function is crucial for a module in PyTorch.\n",
    "    # In our framework, this class outputs a value of the loss function.\n",
    "    def forward(self, x, y, reduction='avg'):\n",
    "        #------\n",
    "        # PLEASE FILL IN\n",
    "        # loss = ...\n",
    "        #------\n",
    "        if reduction == 'sum':\n",
    "            return loss.sum()\n",
    "        else:\n",
    "            return loss.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bwaou1x-gmx3"
   },
   "source": [
    "**Question 1 (0-0.5pt):** What is the objective function for a classification task? In other words, what is nn.NLLLoss in the code above? Pelase write it in mathematical terms.\n",
    "\n",
    "**Answer:**\n",
    "PLEASE FILL IN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kvX88kN-irAD"
   },
   "source": [
    "**Question 2 (0-0.5pt):** In the code above, it is said to use the logarithm of the softmax as the final activation function. Is it correct to use the log-softmax instead of the softmax for making predictions (i.e., picking the most probable label).\n",
    "\n",
    "**Answer:** Yes, it is fine because the logarithm does not change the most probable label, it changes only the probability to the log-probability.\n",
    "\n",
    "PLEASE FILL IN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HVqRQduw3mgm"
   },
   "source": [
    "### 2.2 Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4g9uUFgYP1kT"
   },
   "outputs": [],
   "source": [
    "# PLEASE DO NOT REMOVE\n",
    "def evaluation(test_loader, name=None, model_best=None, epoch=None):\n",
    "    # If available, load the best performing model\n",
    "    if model_best is None:\n",
    "        model_best = torch.load(name + '.model')\n",
    "  \n",
    "    model_best.eval()# set the model to the evaluation mode\n",
    "    loss_test = 0.\n",
    "    loss_error = 0.\n",
    "    N = 0.\n",
    "    # start evaluation\n",
    "    for indx_batch, (test_batch, test_targets) in enumerate(test_loader):\n",
    "        # loss (nll)\n",
    "        loss_test_batch = model_best.forward(test_batch, test_targets, reduction='sum')\n",
    "        loss_test = loss_test + loss_test_batch.item()\n",
    "        # classification error\n",
    "        y_pred = model_best.classify(test_batch)\n",
    "        e = 1.*(y_pred == test_targets)\n",
    "        loss_error = loss_error + (1. - e).sum().item()\n",
    "        # the number of examples\n",
    "        N = N + test_batch.shape[0]\n",
    "    # divide by the number of examples\n",
    "    loss_test = loss_test / N\n",
    "    loss_error = loss_error / N\n",
    "\n",
    "    # Print the performance\n",
    "    if epoch is None:\n",
    "        print(f'-> FINAL PERFORMANCE: nll={loss_test}, ce={loss_error}')\n",
    "    else:\n",
    "        if epoch % 10 == 0:\n",
    "            print(f'Epoch: {epoch}, val nll={loss_test}, val ce={loss_error}')\n",
    "\n",
    "    return loss_test, loss_error\n",
    "\n",
    "# An auxiliary function for plotting the performance curves\n",
    "def plot_curve(name, signal, file_name='curve.pdf', xlabel='epochs', ylabel='nll', color='b-', test_eval=None):\n",
    "    # plot the curve\n",
    "    plt.plot(np.arange(len(signal)), signal, color, linewidth='3', label=ylabel +' val')\n",
    "    # if available, add the final (test) performance\n",
    "    if test_eval is not None:\n",
    "        plt.hlines(test_eval, xmin=0, xmax=len(signal), linestyles='dashed', label=ylabel +' test')\n",
    "        plt.text(len(signal), test_eval, \"{:.3f}\".format(test_eval),)\n",
    "    # set x- and ylabels, add legend, save the figure\n",
    "    plt.xlabel(xlabel), plt.ylabel(ylabel)\n",
    "    plt.legend()\n",
    "    plt.savefig(name + file_name, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YzRd-TiY3puF"
   },
   "source": [
    "### 2.3 Training procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CMhQWbM1QcBM"
   },
   "outputs": [],
   "source": [
    "# PLEASE DO NOT REMOVE!\n",
    "# The training procedure\n",
    "def training(name, max_patience, num_epochs, model, optimizer, training_loader, val_loader):\n",
    "    nll_val = []\n",
    "    error_val = []\n",
    "    best_nll = 1000.\n",
    "    patience = 0\n",
    "\n",
    "    # Main training loop\n",
    "    for e in range(num_epochs):\n",
    "        model.train() # set the model to the training mode\n",
    "        # load batches\n",
    "        for indx_batch, (batch, targets) in enumerate(training_loader):\n",
    "            # calculate the forward pass (loss function for given images and labels)\n",
    "            loss = model.forward(batch, targets)\n",
    "            # remember we need to zero gradients! Just in case!\n",
    "            optimizer.zero_grad()\n",
    "            # calculate backward pass\n",
    "            loss.backward(retain_graph=True)\n",
    "            # run the optimizer\n",
    "            optimizer.step()\n",
    "\n",
    "        # Validation: Evaluate the model on the validation data\n",
    "        loss_e, error_e = evaluation(val_loader, model_best=model, epoch=e)\n",
    "        nll_val.append(loss_e)  # save for plotting\n",
    "        error_val.append(error_e)  # save for plotting\n",
    "\n",
    "        # Early-stopping: update the best performing model and break training if no \n",
    "        # progress is observed.\n",
    "        if e == 0:\n",
    "            torch.save(model, name + '.model')\n",
    "            best_nll = loss_e\n",
    "        else:\n",
    "            if loss_e < best_nll:\n",
    "                torch.save(model, name + '.model')\n",
    "                best_nll = loss_e\n",
    "                patience = 0\n",
    "            else:\n",
    "                patience = patience + 1\n",
    "\n",
    "        if patience > max_patience:\n",
    "            break\n",
    "\n",
    "    # Return nll and classification error.\n",
    "    nll_val = np.asarray(nll_val)\n",
    "    error_val = np.asarray(error_val)\n",
    "\n",
    "    return nll_val, error_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gHYGz3G87nuk"
   },
   "source": [
    "### 2.4 Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "op-YbN-JREqw"
   },
   "source": [
    "#### Initialize dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R_cRaP3gRET1"
   },
   "outputs": [],
   "source": [
    "# PLEASE DO NOT REMOVE\n",
    "# Initialize training, validation and test sets.\n",
    "train_data = Digits(mode='train')\n",
    "val_data = Digits(mode='val')\n",
    "test_data = Digits(mode='test')\n",
    "\n",
    "# Initialize data loaders.\n",
    "training_loader = DataLoader(train_data, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_data, batch_size=64, shuffle=False)\n",
    "test_loader = DataLoader(test_data, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2Lqwm5c3oRia"
   },
   "outputs": [],
   "source": [
    "print(\"How do we get our data from Digits class? \\n\")\n",
    "print(f\"Feature example: {train_data[1][0]}\")\n",
    "print(f\"Feature example shape: {example.shape}\")\n",
    "print(f\"Label example: {train_data[1][1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F5OuaSTOhocZ"
   },
   "outputs": [],
   "source": [
    "print(\"How do we get our data from Pytorch DataLoader class? \\n\")\n",
    "train_features, train_labels = next(iter(training_loader))\n",
    "print(f\"Feature batch shape: {train_features.size()}\")\n",
    "print(f\"Labels batch shape: {train_labels.size()}\")\n",
    "\n",
    "print(\"\\n\\nWhat happens if we reshape a feature batch? \\n\")\n",
    "reshape = Reshape(size=(1,8,8))\n",
    "train_features_reshaped = reshape(train_features)\n",
    "print(f\"Feature batch shape after reshape: {train_features_reshaped.size()}\")\n",
    "\n",
    "print(\"\\n\\nWhat happens if we flatten a reshaped feature batch? \\n\")\n",
    "flatten = Flatten()\n",
    "train_features_flattened = flatten(train_features_reshaped)\n",
    "print(f\"Feature batch shape after flatten: {train_features_flattened.size()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s3ni_8Pv3iuG"
   },
   "source": [
    "#### Initialize hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dnMs4gcLRLEK"
   },
   "outputs": [],
   "source": [
    "# PLEASE DO NOT REMOVE\n",
    "# Hyperparameters\n",
    "# -> data hyperparams\n",
    "D = 64   # input dimension\n",
    "\n",
    "# -> model hyperparams\n",
    "M = 256  # the number of neurons in scale (s) and translation (t) nets\n",
    "K = 10 # the number of labels\n",
    "num_kernels = 32 #the number of kernels for CNN\n",
    "\n",
    "# -> training hyperparams\n",
    "lr = 1e-3 # learning rate\n",
    "wd = 1e-5 # weight decay\n",
    "num_epochs = 1000 # max. number of epochs\n",
    "max_patience = 20 # an early stopping is used, if training doesn't improve for longer than 20 epochs, it is stopped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9VDyHP173vLF"
   },
   "source": [
    "#### Running experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f9T9nXcE3xF2"
   },
   "source": [
    "In the code below, you are supposed to implement architectures for MLP and CNN. For properly implementing these architectures, you can get 0.5pt for each of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AZH7ahwBRP9B"
   },
   "outputs": [],
   "source": [
    "# PLEASE DO NOT REMOVE and FILL IN WHEN NECESSARY!\n",
    "# We will run two models: MLP and CNN\n",
    "names = [\n",
    "         'classifier_mlp', \n",
    "         'classifier_cnn']\n",
    "\n",
    "# loop over models\n",
    "for name in names:\n",
    "    print('\\n-> START {}'.format(name))\n",
    "    # Create a folder (REMEMBER: You must mount your drive if you use Colab!)\n",
    "    if name == 'classifier_mlp':\n",
    "        name = name + '_M_' + str(M)\n",
    "    elif name == 'classifier_cnn':\n",
    "        name = name + '_M_' + str(M) + '_kernels_' + str(num_kernels)\n",
    "  \n",
    "    # Create a folder if necessary\n",
    "    result_dir = os.path.join(results_dir, 'results', name + '/')\n",
    "    if not(os.path.exists(result_dir)):\n",
    "        os.mkdir(result_dir)\n",
    "\n",
    "    # MLP\n",
    "    if name[0:14] == 'classifier_mlp':\n",
    "        #=========\n",
    "        # GRADING: \n",
    "        # 0\n",
    "        # 0.5pt if properly implemented\n",
    "        #=========\n",
    "        #------\n",
    "        # PLEASE FILL IN:\n",
    "        # classnet = nn.Sequential(...)\n",
    "        #\n",
    "        # You are asked here to propose your own architecture\n",
    "        # NOTE: Please remember that the output must be LogSoftmax!\n",
    "        #------\n",
    "\n",
    "    # CNN\n",
    "    elif name[0:14] == 'classifier_cnn':\n",
    "\n",
    "        #=========\n",
    "        # GRADING: \n",
    "        # 0\n",
    "        # 0.5pt if properly implemented\n",
    "        #=========\n",
    "        #------\n",
    "        # PLEASE FILL IN:\n",
    "        # classnet = nn.Sequential(...)\n",
    "        #\n",
    "        # You are asked here to propose your own architecture\n",
    "        # NOTE: Plese note that the images are represented as vectors, thus, you must\n",
    "        # use Reshape(size) as the first layer, and Flatten() after all convolutional\n",
    "        # layers and before linear layers.\n",
    "        # NOTE: Please remember that the output must be LogSoftmax!\n",
    "        #------\n",
    "\n",
    "    # Init ClassifierNN\n",
    "    model = ClassifierNeuralNet(classnet)\n",
    "\n",
    "    # Init OPTIMIZER (here we use ADAMAX)\n",
    "    optimizer = torch.optim.Adamax([p for p in model.parameters() if p.requires_grad == True], lr=lr, weight_decay=wd) \n",
    "\n",
    "    # Training procedure\n",
    "    nll_val, error_val = training(name=result_dir + name,\n",
    "                                  max_patience=max_patience,\n",
    "                                  num_epochs=num_epochs,\n",
    "                                  model=model,\n",
    "                                  optimizer=optimizer,\n",
    "                                  training_loader=training_loader,\n",
    "                                  val_loader=val_loader)\n",
    "  \n",
    "    # The final evaluation (on the test set)\n",
    "    test_loss, test_error = evaluation(name=result_dir + name, test_loader=test_loader)\n",
    "    # write the results to a file\n",
    "    f = open(result_dir + name + '_test_loss.txt', \"w\")\n",
    "    f.write('NLL: ' + str(test_loss) + '\\nCE: ' + str(test_error))\n",
    "    f.close()\n",
    "    # create curves\n",
    "    plot_curve(result_dir + name, nll_val, file_name='_nll_val_curve.pdf', ylabel='nll', test_eval=test_loss)\n",
    "    plot_curve(result_dir + name, error_val, file_name='_ca_val_curve.pdf', ylabel='ce', color='r-', test_eval=test_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oFX-DzH9ftPg"
   },
   "source": [
    "## 2.5 Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2-TFtGdZfz3a"
   },
   "source": [
    "**Question 3 (0-0.5pt)**: Please compare the convergence of MLP and CNN in terms of the loss function and the classification error.\n",
    "\n",
    "**Answer**: PLEASE FILL IN and PASTE THE IMAGES HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0f2P57ZmlwXz"
   },
   "source": [
    "**Question 4 (0-0.5pt)**: In general, for a properly picked architectures, a CNN should work better than an MLP. Did you notice that? Why (in general) CNNs are better suited to images than MLPs?\n",
    "\n",
    "**Answer**: PLEASE FILL IN and PASTE THE IMAGES HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1QJ_mRdT7Ais"
   },
   "source": [
    "## 3 Application to Street House View Numbers (SVHN) (6pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YHhUUaYL7GEx"
   },
   "source": [
    "Please repeat (some) of the code in the previous section and apply a bigger convolutional neural network (CNN) to the following dataset:\n",
    "\n",
    "http://ufldl.stanford.edu/housenumbers/\n",
    "\n",
    "Please follow the following steps:\n",
    "1. (1pt) Create appropriate Dataset class. Please remember to use the original training data and test data, and also to create a validation set from the traning data (at least 10% of the training examples). **Do not use extra examples!**\n",
    "2. (1pt) Implement an architecture that will give at most 0.1 classification error. For instance, see this paper as a reference: https://arxiv.org/pdf/1204.3968.pdf#:~:text=The%20SVHN%20classification%20dataset%20%5B8,set%20of%20more%20difficult%20samples\n",
    "3. (1pt) Think of an extra component that could improve the performance (e.g., a regularization, specific activation functions).\n",
    "4. (1pt) Provide a good explanation of the applied architecture and a description of all components.\n",
    "5. (2pt) Analyze the results.\n",
    "\n",
    "**Please be very precise, comment your code and provide a comprehensive and clear analysis.**"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "assignment_4.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
